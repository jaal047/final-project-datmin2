{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3fce35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57ab7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_folder(path):\n",
    "    lst = []\n",
    "    for img in glob.glob(path+'*.jpg'):\n",
    "        n= plt.imread(img)\n",
    "        lst.append(n)\n",
    "    return np.array(lst)\n",
    "\n",
    "# awake_img = np.array(awake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecd9add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# awake_path = \"C:/Users/ACER/OneDrive - Universitas Airlangga/KULIAH/semester 5/bbb data mining/final_project/final-project-datmin2/images/awake/awake\"\n",
    "# drowsy_path = \"C:/Users/ACER/OneDrive - Universitas Airlangga/KULIAH/semester 5/bbb data mining/final_project/final-project-datmin2/images/drowsy/drowsy\"\n",
    "awake_path = \"/images/awake/awake\"\n",
    "drowsy_path = \"/images/drowsy/drowsy\"\n",
    "awake_img = load_img_folder(awake_path)\n",
    "drowsy_img = load_img_folder(drowsy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719bef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 480, 640, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awake_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "578790a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 480, 640, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drowsy_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96ab4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "mp_drawing  = mp.solutions.drawing_utils\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Landmark points corresponding to left eye\n",
    "all_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n",
    "# flatten and remove duplicates\n",
    "all_left_eye_idxs = set(np.ravel(all_left_eye_idxs)) \n",
    "\n",
    "# Landmark points corresponding to right eye\n",
    "all_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\n",
    "all_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n",
    "\n",
    "# Combined for plotting - Landmark points for both eye\n",
    "all_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n",
    "\n",
    "# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\n",
    "chosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\n",
    "chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
    "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e07e3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point_1, point_2):\n",
    "    \"\"\"Calculate l2-norm between two points\"\"\"\n",
    "    dist = sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "    return dist\n",
    "\n",
    "def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Calculate Eye Aspect Ratio for one eye.\n",
    "\n",
    "    Args:\n",
    "        landmarks: (list) Detected landmarks list\n",
    "        refer_idxs: (list) Index positions of the chosen landmarks\n",
    "                            in order P1, P2, P3, P4, P5, P6\n",
    "        frame_width: (int) Width of captured frame\n",
    "        frame_height: (int) Height of captured frame\n",
    "\n",
    "    Returns:\n",
    "        ear: (float) Eye aspect ratio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Compute the euclidean distance between the horizontal\n",
    "        coords_points = []\n",
    "        for i in refer_idxs:\n",
    "            lm = landmarks[i]\n",
    "            coord = denormalize_coordinates(lm.x, lm.y, \n",
    "                                             frame_width, frame_height)\n",
    "            coords_points.append(coord)\n",
    "\n",
    "        # Eye landmark (x, y)-coordinates\n",
    "        P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "        P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "        P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    "\n",
    "    except:\n",
    "        ear = 0.0\n",
    "        coords_points = None\n",
    "\n",
    "    return ear, coords_points\n",
    "\n",
    "def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "    \"\"\"Calculate Eye aspect ratio\"\"\"\n",
    "\n",
    "    left_ear, left_lm_coordinates = get_ear(\n",
    "                                      landmarks, \n",
    "                                      left_eye_idxs, \n",
    "                                      image_w, \n",
    "                                      image_h\n",
    "                                    )\n",
    "    right_ear, right_lm_coordinates = get_ear(\n",
    "                                      landmarks, \n",
    "                                      right_eye_idxs, \n",
    "                                      image_w, \n",
    "                                      image_h\n",
    "                                    )\n",
    "    Avg_EAR = (left_ear + right_ear) / 2.0\n",
    "\n",
    "    return Avg_EAR, (left_lm_coordinates, right_lm_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5f1a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_ear(img_read, ear_thresh=0.2):\n",
    "    image = np.ascontiguousarray(img_read)\n",
    "    imgH, imgW, _ = image.shape\n",
    "    custom_chosen_lmk_image = image.copy()\n",
    "    \n",
    "    with mp_facemesh.FaceMesh(refine_landmarks=True) as face_mesh:\n",
    "        results = face_mesh.process(image).multi_face_landmarks\n",
    "        \n",
    "        if results:\n",
    "            for face_id, face_landmarks in enumerate(results):\n",
    "                landmarks = face_landmarks.landmark\n",
    "                EAR, _ = calculate_avg_ear(\n",
    "                          landmarks, \n",
    "                          chosen_left_eye_idxs, \n",
    "                          chosen_right_eye_idxs, \n",
    "                          imgW, \n",
    "                          imgH\n",
    "                      )\n",
    "                if EAR < ear_thresh:\n",
    "                    return [EAR, 'drowsy']\n",
    "                elif EAR >= ear_thresh:\n",
    "                    return [EAR, 'awake']\n",
    "#                 return EAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f312411",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_awake = []\n",
    "for i in range(len(awake_img)):\n",
    "    try:\n",
    "        ear_result = final_ear(awake_img[i])[1]\n",
    "        hasil_awake.append(ear_result)    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6004fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_drowsy = []\n",
    "for i in range(len(drowsy_img)):\n",
    "    try:\n",
    "        ear_result = final_ear(drowsy_img[i])[1]\n",
    "        hasil_drowsy.append(ear_result)    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f89f9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "91\n",
      "94\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(awake_img))\n",
    "print(len(hasil_awake))\n",
    "\n",
    "print(len(drowsy_img))\n",
    "print(len(hasil_drowsy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b08cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awake'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ear(drowsy_img[i])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "757dd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = np.array([[hasil_awake.count('awake'), hasil_awake.count('drowsy')],\n",
    "              [hasil_drowsy.count('awake'), hasil_drowsy.count('drowsy')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14dfe2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86,  5],\n",
       "       [36, 57]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a3f2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metode = []\n",
    "list_acc = []\n",
    "list_rec = []\n",
    "list_pre = []\n",
    "list_f1s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12c5ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(sum(con_matrix))\n",
    "# goodness ear predict\n",
    "TP = con_matrix[0][0]\n",
    "FN = con_matrix[0][1]\n",
    "FP = con_matrix[1][0]\n",
    "TN = con_matrix[1][1]\n",
    "\n",
    "ear_metode = 'Eye Aspect Ratio'\n",
    "ear_acc = (TP+TN)/(TP+TN+FN+FP)\n",
    "ear_rec = (TP)/(TP+FN)\n",
    "ear_pre = (TP)/(TP+FP)\n",
    "ear_f1s = (2*TP)/(2*TP+FP+FN)\n",
    "\n",
    "list_metode.append(ear_metode)\n",
    "list_acc.append(ear_acc)\n",
    "list_rec.append(ear_rec)\n",
    "list_pre.append(ear_pre)\n",
    "list_f1s.append(ear_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd0eed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ffdd6_row0_col1, #T_ffdd6_row0_col2, #T_ffdd6_row0_col3, #T_ffdd6_row0_col4 {\n",
       "  background-color: #f3f0f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ffdd6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ffdd6_level0_col0\" class=\"col_heading level0 col0\" >metode</th>\n",
       "      <th id=\"T_ffdd6_level0_col1\" class=\"col_heading level0 col1\" >akurasi</th>\n",
       "      <th id=\"T_ffdd6_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_ffdd6_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
       "      <th id=\"T_ffdd6_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ffdd6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ffdd6_row0_col0\" class=\"data row0 col0\" >Eye Aspect Ratio</td>\n",
       "      <td id=\"T_ffdd6_row0_col1\" class=\"data row0 col1\" >0.777174</td>\n",
       "      <td id=\"T_ffdd6_row0_col2\" class=\"data row0 col2\" >0.945055</td>\n",
       "      <td id=\"T_ffdd6_row0_col3\" class=\"data row0 col3\" >0.704918</td>\n",
       "      <td id=\"T_ffdd6_row0_col4\" class=\"data row0 col4\" >0.807512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b1be43a850>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "summ = pd.DataFrame({\"metode\":list_metode,\n",
    "                    'akurasi':list_acc,\n",
    "                    'recall':list_rec,\n",
    "                    'precision': list_pre,\n",
    "                    'f1-score': list_f1s})\n",
    "summ = summ.sort_values(by=['akurasi'],ascending=False).reset_index(drop=True)\n",
    "cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "summ.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1c3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "005f91c35f334889d9bcc0108a4280eae9719191ea748edfbbff9620a71a3376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
